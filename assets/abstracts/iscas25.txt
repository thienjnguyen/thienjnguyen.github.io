This paper presents a near-imager inference hardware module enabling complex spatio-temporal pattern recognition (e.g., hand gesture or human fall). It relies on an algorithmic-architecture co-design approach leading to high accuracy at a low power consumption, optimized to handle raw data provided by an imager (row-by-row). Thanks to its 2-part deep learning model, leveraging both pipelined RTL design and near-SRAM computing, our 1Mb ASIC exhibits an estimated power consumption below 200ÂµW at 20fps. Among our contributions is the definition (with its dedicated training) of fully binarized Gated Recurrent Units compatible with an optimized near-SRAM hardware.